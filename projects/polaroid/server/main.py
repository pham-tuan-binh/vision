from fastapi import FastAPI, File, UploadFile, Form, HTTPException
from fastapi.responses import StreamingResponse
from PIL import Image
import requests
import os
from dotenv import load_dotenv
import logging
from io import BytesIO
import uuid
from pathlib import Path
from google import genai
from google.genai import types

# Load environment variables
load_dotenv()

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Initialize FastAPI app
app = FastAPI(
    title="Image Router API Server",
    description="Image editing using Image Router API with advanced prompt generation",
    version="1.1.0"
)

# Create images directory if it doesn't exist
IMAGES_DIR = Path("images")
IMAGES_DIR.mkdir(exist_ok=True)

# Get API keys from environment
API_KEY = os.getenv("IMAGEROUTER_API_KEY")
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")  # Changed from GEMINI_API_KEY

if not API_KEY:
    logger.error("IMAGEROUTER_API_KEY environment variable is required")
    raise ValueError("IMAGEROUTER_API_KEY environment variable is required")

if not GEMINI_API_KEY:
    logger.error("GOOGLE_API_KEY environment variable is required")
    raise ValueError("GOOGLE_API_KEY environment variable is required")

# Configure Google AI client
client_genai = genai.Client(api_key=GEMINI_API_KEY)

IMAGE_ROUTER_URL = "https://api.imagerouter.io/v1/openai/images/edits"

def save_image(image: Image.Image, image_id: str, filename: str) -> str:
    """
    Save image to the images directory
    
    Args:
        image: PIL Image object
        image_id: Unique identifier for the image session
        filename: Name of the file (e.g., 'input.jpg', 'output.jpg')
    
    Returns:
        str: Path where the image was saved
    """
    # Create subdirectory for this image_id
    image_dir = IMAGES_DIR / image_id
    image_dir.mkdir(exist_ok=True)
    
    # Save the image
    file_path = image_dir / filename
    
    # Save as JPEG with high quality
    if filename.endswith('.jpg'):
        image.save(file_path, format='JPEG', quality=95)
    else:
        image.save(file_path)
    
    logger.info(f"Saved image to {file_path}")
    return str(file_path)

def downscale_image(image: Image.Image, target_width: int = 240, target_height: int = 320) -> Image.Image:
    """
    Crop and scale image to exact target resolution (240x320) while maintaining aspect ratio

    Args:
        image: PIL Image object
        target_width: Target width (default: 240)
        target_height: Target height (default: 320)

    Returns:
        PIL Image object cropped and resized to exactly target dimensions
    """
    # Get original dimensions
    original_width, original_height = image.size
    
    # If image is horizontal (wider than tall), rotate to vertical
    if original_width > original_height:
        image = image.rotate(90, expand=True)
        logger.info(f"Rotated horizontal image to vertical")
        # Update dimensions after rotation
        original_width, original_height = image.size
    
    # Calculate aspect ratios
    original_aspect = original_width / original_height
    target_aspect = target_width / target_height
    
    # Now only check if image is taller than target aspect ratio
    if original_aspect < target_aspect:
        # Image is taller than target - crop the top/bottom
        crop_width = original_width
        crop_height = int(crop_width / target_aspect)
        # Center the crop
        left = 0
        top = (original_height - crop_height) // 2
        right = crop_width
        bottom = top + crop_height
        
        # Crop the image to the target aspect ratio
        cropped_image = image.crop((left, top, right, bottom))
    else:
        # Image aspect ratio is wider than or equal to target - use whole image
        cropped_image = image
    
    # Resize to exact target dimensions
    resized_image = cropped_image.resize((target_width, target_height), Image.Resampling.LANCZOS)
    
    logger.info(f"Processed image from {original_width}x{original_height} to exactly {target_width}x{target_height}")
    return resized_image

def generate_enhanced_prompt(image: Image.Image, style_prompt: str) -> str:
    """
    Use Google's Gemini AI to analyze the image and generate an enhanced prompt
    
    Args:
        image: PIL Image object to analyze
        style_prompt: The style/transformation the user wants
    
    Returns:
        str: Enhanced prompt generated by Gemini AI
    """
    try:
        # Create the analysis prompt for Gemini
        analysis_prompt = f"""
        Analyze this image and create a detailed, specific prompt for image editing based on the user's desired style: "{style_prompt}"

        Please provide:
        1. A brief description of what you see in the image (objects, colors, composition, lighting, etc.)
        2. An enhanced prompt that combines the image content with the desired style transformation

        The enhanced prompt should be:
        - Specific and detailed
        - Focused on the visual transformation requested
        - Include relevant details about colors, lighting, textures, and composition
        - Be optimized for AI image generation/editing models
        - Maximum 50 words

        User's style request: {style_prompt}

        Please respond with just the enhanced prompt, no additional explanation.
        """
        
        # Convert image to bytes for the API
        img_byte_arr = BytesIO()
        image.save(img_byte_arr, format='PNG')
        img_byte_arr.seek(0)
        
        # Create image part using the new SDK
        image_part = types.Part.from_bytes(
            data=img_byte_arr.getvalue(),
            mime_type='image/png'
        )
        
        # Generate content with image and text
        response = client_genai.models.generate_content(
            model='gemini-2.0-flash-001',
            contents=[analysis_prompt, image_part],
            config=types.GenerateContentConfig(
                temperature=0.7,
                max_output_tokens=300
            )
        )
        
        enhanced_prompt = response.text.strip()
        
        logger.info(f"Generated enhanced prompt: {enhanced_prompt}")
        return enhanced_prompt
        
    except Exception as e:
        logger.error(f"Error generating enhanced prompt: {e}")
        # Fallback to original prompt if Gemini fails
        logger.info("Falling back to original prompt due to Gemini API error")
        return style_prompt

def edit_image_with_router(files: dict, prompt: str, model: str = "openai/gpt-image-1") -> dict:
    """
    Edit image using the Image Router API
    
    Args:
        files: Prepared files dict for upload
        prompt: Text prompt for the editing task
        model: Model to use for image editing
    
    Returns:
        dict: Response from the Image Router API
    """
    try:
        headers = {
            "Authorization": f"Bearer {API_KEY}"
        }
        
        # Prepare payload
        payload = {
            "prompt": prompt,
            "model": model,
        }
        
        logger.info(f"Sending request to Image Router API with prompt: {prompt} and model: {model}")
        
        # Make request to Image Router API
        response = requests.post(
            IMAGE_ROUTER_URL,
            files=files,
            data=payload,
            headers=headers,
            timeout=60  # 60 seconds timeout
        )
        
        # Check if request was successful
        response.raise_for_status()
        
        logger.info("Successfully received response from Image Router API")
        return response.json()
        
    except requests.exceptions.RequestException as e:
        logger.error(f"Request to Image Router API failed: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"Failed to process image: {str(e)}"
        )
    except Exception as e:
        logger.error(f"Unexpected error: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"Internal server error: {str(e)}"
        )

@app.get("/")
async def root():
    """Health check endpoint"""
    return {"message": "Image Router API Server is running"}

@app.post("/upload")
async def upload_and_edit(
    image: UploadFile = File(..., description="Input image file"),
    prompt: str = Form("Pixelize this image in a retro style", description="Text prompt for image editing"),
    model: str = Form("google/gemini-2.0-flash-exp", description="Model to use for image editing")
):
    """
    Edit image using the Image Router API
    
    Args:
        image: Input image file (JPEG, PNG, etc.)
        prompt: Text prompt describing the desired edits
        model: Model to use (default: openai/gpt-image-1)
    
    Returns:
        StreamingResponse: Edited image as a downloadable file
    """
    try:
        # Validate file type
        if not image.content_type.startswith("image/"):
            raise HTTPException(
                status_code=400,
                detail="File must be an image"
            )
        
        # Read and process the uploaded image
        image_data = await image.read()
        original_image = Image.open(BytesIO(image_data))
        
        # Generate unique ID for this request
        image_id = str(uuid.uuid4())
        
        # Convert to RGB if necessary (for RGBA images)
        if original_image.mode in ("RGBA", "LA"):
            background = Image.new("RGB", original_image.size, (255, 255, 255))
            background.paste(original_image, mask=original_image.split()[-1])
            original_image = background
        elif original_image.mode != "RGB":
            original_image = original_image.convert("RGB")
        
        # Save original image (before downscaling)
        save_image(original_image, image_id, "input.jpg")
        
        # Downscale the image to 320x240
        downscaled_image = downscale_image(original_image, target_width=240, target_height=320)
        
        # Convert downscaled image to bytes for API upload
        img_byte_arr = BytesIO()
        downscaled_image.save(img_byte_arr, format='PNG')
        img_byte_arr.seek(0)
        
        logger.info(f"Processing downscaled image (ID: {image_id}) with prompt: {prompt} using model: {model}")
        
        # Prepare files for upload using the downscaled image
        files = {
            "image[]": ("image.png", img_byte_arr, "image/png")
        }
        
        # Call the Image Router API
        result = edit_image_with_router(files=files, prompt=prompt, model=model)
        
        # Extract the image URL from the response
        if not result.get("data") or not result["data"]:
            raise HTTPException(
                status_code=500,
                detail="No image data returned from Image Router API"
            )
        
        image_url = result["data"][0].get("url")
        if not image_url:
            raise HTTPException(
                status_code=500,
                detail="No image URL found in response"
            )
        
        logger.info(f"Fetching image from URL: {image_url}")
        
        # Download the image from the URL
        image_response = requests.get(image_url, timeout=30)
        image_response.raise_for_status()
        
        # Load the generated image
        generated_image = Image.open(BytesIO(image_response.content))
        
        # Downscale the output image to 240x320 as well
        downscaled_output = downscale_image(generated_image, target_width=240, target_height=320)
        
        # Save the downscaled output image as JPG
        save_image(downscaled_output, image_id, "output.jpg")
        
        # Convert downscaled output to bytes for response as JPG
        output_byte_arr = BytesIO()
        downscaled_output.save(output_byte_arr, format='JPEG', quality=95)
        output_byte_arr.seek(0)
        
        # Return the downscaled image as a streaming response
        return StreamingResponse(
            BytesIO(output_byte_arr.read()),
            media_type="image/jpeg",
            headers={
                "Content-Disposition": "attachment; filename=edited_image.jpg",
                "X-Image-ID": image_id  # Include image ID in response headers
            }
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error in upload endpoint: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"Failed to edit image: {str(e)}"
        )

@app.post("/upload_adv")
async def upload_and_edit_advanced(
    image: UploadFile = File(..., description="Input image file"),
    prompt: str = Form("Ghibli style but everything composition should be the same", description="Style prompt for image editing - will be enhanced by AI"),
    model: str = Form("google/gemini-2.0-flash-exp", description="Model to use for image editing")
):
    """
    Advanced image editing using Google Gemini AI for prompt enhancement
    
    This endpoint first analyzes the uploaded image using Google's Gemini AI
    to understand the content, then generates an enhanced prompt based on the
    user's style request and the image analysis.
    
    Args:
        image: Input image file (JPEG, PNG, etc.)
        prompt: Style/transformation prompt (will be enhanced by Gemini AI)
        model: Model to use for image editing (default: stabilityai/sd3)
    
    Returns:
        StreamingResponse: Edited image as a downloadable file with enhanced prompt
    """
    try:
        # Validate file type
        if not image.content_type.startswith("image/"):
            raise HTTPException(
                status_code=400,
                detail="File must be an image"
            )
        
        # Read and process the uploaded image
        image_data = await image.read()
        original_image = Image.open(BytesIO(image_data))
        
        # Generate unique ID for this request
        image_id = str(uuid.uuid4())
        
        # Convert to RGB if necessary (for RGBA images)
        if original_image.mode in ("RGBA", "LA"):
            background = Image.new("RGB", original_image.size, (255, 255, 255))
            background.paste(original_image, mask=original_image.split()[-1])
            original_image = background
        elif original_image.mode != "RGB":
            original_image = original_image.convert("RGB")
        
        # Save original image (before downscaling)
        save_image(original_image, image_id, "input.jpg")
        
        logger.info(f"Generating enhanced prompt for image (ID: {image_id}) with style: {prompt}")
        
        # Generate enhanced prompt using Gemini AI
        enhanced_prompt = generate_enhanced_prompt(original_image, prompt)
        
        # Downscale the image to 240x320
        downscaled_image = downscale_image(original_image, target_width=240, target_height=320)
        
        # Convert downscaled image to bytes for API upload
        img_byte_arr = BytesIO()
        downscaled_image.save(img_byte_arr, format='PNG')
        img_byte_arr.seek(0)
        
        logger.info(f"Processing downscaled image (ID: {image_id}) with enhanced prompt: {enhanced_prompt} using model: {model}")
        
        # Prepare files for upload using the downscaled image
        files = {
            "image[]": ("image.png", img_byte_arr, "image/png")
        }
        
        # Call the Image Router API with enhanced prompt
        result = edit_image_with_router(files=files, prompt=enhanced_prompt, model=model)
        
        # Extract the image URL from the response
        if not result.get("data") or not result["data"]:
            raise HTTPException(
                status_code=500,
                detail="No image data returned from Image Router API"
            )
        
        image_url = result["data"][0].get("url")
        if not image_url:
            raise HTTPException(
                status_code=500,
                detail="No image URL found in response"
            )
        
        logger.info(f"Fetching image from URL: {image_url}")
        
        # Download the image from the URL
        image_response = requests.get(image_url, timeout=30)
        image_response.raise_for_status()
        
        # Load the generated image
        generated_image = Image.open(BytesIO(image_response.content))
        
        # Downscale the output image to 240x320 as well
        downscaled_output = downscale_image(generated_image, target_width=240, target_height=320)
        
        # Save the downscaled output image as JPG
        save_image(downscaled_output, image_id, "output.jpg")
        
        # Convert downscaled output to bytes for response as JPG
        output_byte_arr = BytesIO()
        downscaled_output.save(output_byte_arr, format='JPEG', quality=95)
        output_byte_arr.seek(0)
        
        # Return the downscaled image as a streaming response
        return StreamingResponse(
            BytesIO(output_byte_arr.read()),
            media_type="image/jpeg",
            headers={
                "Content-Disposition": "attachment; filename=edited_image_advanced.jpg",
                "X-Image-ID": image_id,
                "X-Original-Prompt": prompt,
                "X-Enhanced-Prompt": enhanced_prompt[:200] + "..." if len(enhanced_prompt) > 200 else enhanced_prompt
            }
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error in upload_adv endpoint: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"Failed to edit image with advanced processing: {str(e)}"
        )

@app.get("/health")
async def health_check():
    """Health check endpoint"""
    return {"status": "healthy", "service": "imagerouter-api"}

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)